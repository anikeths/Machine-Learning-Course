{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-08T05:06:55.722966Z",
     "start_time": "2022-04-08T05:06:55.363003Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>BldgType</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>8450</td>\n",
       "      <td>1710.0</td>\n",
       "      <td>2003</td>\n",
       "      <td>2008</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>11250</td>\n",
       "      <td>1786.0</td>\n",
       "      <td>2001</td>\n",
       "      <td>2008</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>9550</td>\n",
       "      <td>1717.0</td>\n",
       "      <td>1915</td>\n",
       "      <td>2006</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>14260</td>\n",
       "      <td>2198.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>2008</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>14115</td>\n",
       "      <td>1362.0</td>\n",
       "      <td>1993</td>\n",
       "      <td>2009</td>\n",
       "      <td>143000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id BldgType  LotArea  GrLivArea  YearBuilt  YrSold  SalePrice\n",
       "0   1     1Fam     8450     1710.0       2003    2008     208500\n",
       "2   3     1Fam    11250     1786.0       2001    2008     223500\n",
       "3   4     1Fam     9550     1717.0       1915    2006     140000\n",
       "4   5     1Fam    14260     2198.0       2000    2008     250000\n",
       "5   6     1Fam    14115     1362.0       1993    2009     143000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('house_prices.csv')\n",
    "df_new = df[df.BldgType=='1Fam'].copy()\n",
    "df_new = df_new.dropna()\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T04:10:52.113775Z",
     "start_time": "2022-04-07T04:10:52.105130Z"
    }
   },
   "outputs": [],
   "source": [
    "train_raw = df_new[df_new.YrSold < 2010].reset_index(drop=True)\n",
    "test_raw = df_new[df_new.YrSold >= 2010].reset_index(drop=True)\n",
    "train = train_raw[['LotArea','GrLivArea','YearBuilt','YrSold','SalePrice']].copy()\n",
    "test = test_raw[['LotArea','GrLivArea','YearBuilt','YrSold','SalePrice']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T04:10:52.628737Z",
     "start_time": "2022-04-07T04:10:52.622149Z"
    }
   },
   "outputs": [],
   "source": [
    "features = list(train.columns)\n",
    "target = \"SalePrice\"\n",
    "features.remove(target)\n",
    "\n",
    "X = train_raw[features].copy()\n",
    "y = train_raw[target].copy()\n",
    "\n",
    "X_test = test[features].copy()\n",
    "y_test = test[target].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T04:10:53.926543Z",
     "start_time": "2022-04-07T04:10:53.445022Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example:** Split training data in to new training data and validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T04:10:53.932606Z",
     "start_time": "2022-04-07T04:10:53.928336Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, \n",
    "                                                      y, \n",
    "                                                      test_size=0.2, \n",
    "                                                      random_state=2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T04:10:54.626747Z",
     "start_time": "2022-04-07T04:10:54.619525Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LotArea</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YrSold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>9855</td>\n",
       "      <td>1689.0</td>\n",
       "      <td>1956</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>14230</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>2007</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>12435</td>\n",
       "      <td>1792.0</td>\n",
       "      <td>2001</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854</th>\n",
       "      <td>16545</td>\n",
       "      <td>2450.0</td>\n",
       "      <td>1998</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>14154</td>\n",
       "      <td>2172.0</td>\n",
       "      <td>2006</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     LotArea  GrLivArea  YearBuilt  YrSold\n",
       "268     9855     1689.0       1956    2009\n",
       "16     14230     1600.0       2007    2009\n",
       "141    12435     1792.0       2001    2008\n",
       "854    16545     2450.0       1998    2009\n",
       "245    14154     2172.0       2006    2007"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example:** Find the best **alpha** for Lasso using **validation score**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T04:22:50.401326Z",
     "start_time": "2022-04-07T04:22:50.397994Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from sklearn.preprocessing import PolynomialFeatures, MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T04:24:09.123378Z",
     "start_time": "2022-04-07T04:24:09.039571Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "avalues=list(np.logspace(-3, 3, 13))\n",
    "mse = []\n",
    "for a in avalues:\n",
    "    steps = [('poly', PolynomialFeatures(degree=3)),\n",
    "             ('rescale', MinMaxScaler()),\n",
    "             ('lr', Ridge(alpha=a, max_iter=100000))]\n",
    "    model = Pipeline(steps)\n",
    "    model = model.fit(X_train, y_train)\n",
    "    mse.append(mean_squared_error(y_valid, model.predict(X_valid)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n"
     ]
    }
   ],
   "source": [
    "avalues=list(np.logspace(-3, 3, 13))\n",
    "mse = []\n",
    "alpha = 0\n",
    "minError = float('inf')\n",
    "for a in avalues:\n",
    "    steps = [('poly', PolynomialFeatures(degree=3)),\n",
    "             ('rescale', MinMaxScaler()),\n",
    "             ('lr', Ridge(alpha=a, max_iter=100000))]\n",
    "    model = Pipeline(steps)\n",
    "    model = model.fit(X_train, y_train)\n",
    "    mse.append(mean_squared_error(y_valid, model.predict(X_valid)))\n",
    "    if mean_squared_error(y_valid, model.predict(X_valid)) < minError:\n",
    "        minError = mean_squared_error(y_valid, model.predict(X_valid))\n",
    "        alpha = a\n",
    "        \n",
    "print(alpha)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T04:24:09.425106Z",
     "start_time": "2022-04-07T04:24:09.421366Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T04:24:10.377935Z",
     "start_time": "2022-04-07T04:24:09.994445Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Loss vs. alpha using Ridge')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(avalues, mse, marker='*')\n",
    "plt.xscale('log')\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('MSE')\n",
    "plt.title('Loss vs. alpha using Ridge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Question:</font> What are training, validation, and testing data for? Why did we use validation data to find the best **alpha**? Can we use test data to find the best **alpha**?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Dataset: The sample of data used to fit the model.\n",
    "### The actual dataset that we use to train the model (weights and biases in the case of a Neural Network). The model sees and learns from this data.\n",
    "\n",
    "\n",
    "\n",
    "### Validation Dataset : for parameter estimation\n",
    "### Validation Dataset: The sample of data used to provide an unbiased evaluation of a model fit on the training dataset while tuning model hyperparameters. The evaluation becomes more biased as skill on the validation dataset is incorporated into the model configuration.\n",
    "\n",
    "\n",
    "### Test Dataset : for final evaluation\n",
    "### Test Dataset: The sample of data used to provide an unbiased evaluation of a final model fit on the training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-fold Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Assignment:</font> Use **KFold** instead of **train_test_split** to find the best **alpha**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T04:24:28.395933Z",
     "start_time": "2022-04-07T04:24:28.392684Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=2022)\n",
    "kf.get_n_splits(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T04:25:19.025512Z",
     "start_time": "2022-04-07T04:25:17.523653Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train length 698 Train index: [0 1 2 3 4] Valid length 175 Valid index: [ 7 10 27 32 34]\n",
      "Train length 698 Train index: [0 2 3 5 7] Valid length 175 Valid index: [ 1  4  6 13 15]\n",
      "Train length 698 Train index: [0 1 3 4 5] Valid length 175 Valid index: [ 2  9 17 21 22]\n",
      "Train length 699 Train index: [0 1 2 4 6] Valid length 174 Valid index: [ 3  5  8 20 30]\n",
      "Train length 699 Train index: [1 2 3 4 5] Valid length 174 Valid index: [ 0 11 12 14 18]\n",
      "Best alpha is 0.001\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "avalues=list(np.logspace(-3, 3, 13))\n",
    "mse_kfold = []\n",
    "minError, alpha = float('inf'), 0\n",
    "for train_index, valid_index in kf.split(X,y):\n",
    "    X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n",
    "    y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n",
    "    print('Train length', len(train_index), 'Train index:', train_index[0:5], \n",
    "          'Valid length', len(valid_index),'Valid index:',valid_index[0:5])\n",
    "    mse = []\n",
    "    for a in avalues:\n",
    "        #fill in your own code here\n",
    "        steps = [('poly', PolynomialFeatures(degree=3)),\n",
    "         ('rescale', MinMaxScaler()),\n",
    "         ('lr', Ridge(alpha=a, max_iter=100000))]\n",
    "        model = Pipeline(steps)\n",
    "        model = model.fit(X_train, y_train)\n",
    "        mse.append(mean_squared_error(y_valid, model.predict(X_valid)))   \n",
    "        if mean_squared_error(y_valid, model.predict(X_valid)) < minError:\n",
    "            minError = mean_squared_error(y_valid, model.predict(X_valid))\n",
    "            alpha = a\n",
    "print(\"Best alpha is\",alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "avalues=list(np.logspace(-3, 3, 13))\n",
    "mse_kfold = []\n",
    "\n",
    "for train_index, valid_index in kf.split(X,y):\n",
    "    X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n",
    "    y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n",
    "    print('Train length', len(train_index), 'Train index:', train_index[0:5], \n",
    "          'Valid length', len(valid_index),'Valid index:',valid_index[0:5])\n",
    "    mse = []\n",
    "    for a in avalues:\n",
    "        #fill in your own code here\n",
    "        steps = [('poly', PolynomialFeatures(degree=3)),\n",
    "         ('rescale', MinMaxScaler()),\n",
    "         ('lr', Ridge(alpha=a, max_iter=100000))]\n",
    "        model = Pipeline(steps)\n",
    "        model = model.fit(X_train, y_train)\n",
    "        mse.append(mean_squared_error(y_valid, model.predict(X_valid)))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Question:</font> What is the difference between **KFold** and **train_test_split**? What is the advantages and disadvanteges of k-fold cross validation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Difference between KFold and train_test_split:\n",
    "\n",
    "\n",
    "### Train-Test Split:  So when we use train_test_split, it's randomly taking 80% of the samples and assigning them to the training set and the other 20% are assigned to the test set. \n",
    "\n",
    "### Cross-Validation: The way cross-validation works is (with k=10) it takes the first 10% of the data (not randomized) as the test data, and the remaining 90% is used as training, it evaluates test accuracy and stores it. It then takes the second 10% of the data for test, and trains on the first 10% and last 80% (which is the remaining 90%), it also stores the accuracy score derived here. It does this 10 times until there is  accuracy scores for each of the 10 validation tests (each on a different test set), the score that is got at the end will be the mean of these accuracies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Advantages of k-fold cross-validation.\n",
    "### It ‘validates’ the performance of your model on multiple ‘folds’ of your data.\n",
    "### It can balance out the predicted features’ classes if you are dealing with an unbalanced dataset.\n",
    "### Because of 1 and 3 it gives you a more stable answer as to how your model performs on that data.\n",
    "\n",
    "\n",
    "### Disadvantages:\n",
    "\n",
    "### K-fold doesn’t really work well with sequential data (a time series of some kind). If you use it you’d be predicting past values with future value training, which is not a good way to go about things.\n",
    "\n",
    "### If you just trust the K-fold final aggregated score for your model, imagine r-squared of 0.95, you will miss a lot of information about your models’ performance like the spikes i described above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Assignment:</font> By now, we have only tuned the value of **alpha**. Actually, **degree** in **PolynomialFeatures** is also a hyper parameter. Can we find the best values for both of them? You can try to use **GridSearchCV**, and also **make_scorer**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-08T05:07:05.842214Z",
     "start_time": "2022-04-08T05:07:05.837957Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "avalues=list(np.logspace(-3, 3, 13))\n",
    "tuned_parameters = [{'lr__alpha':avalues,'poly__degree':range(1,10)}]\n",
    "my_mse = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
